name: aml-mlops-cicd

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AZURE_RESOURCE_GROUP:  MSFT-AI-Class
  AZURE_ML_WORKSPACE:    MyFirstWorkSpace
  AZURE_LOCATION:        eastus
  COMPONENT_NAME:        train_random_forest
  COMPONENT_FILE:        aml/components/train.yml
  PIPELINE_FILE:         aml/pipeline.yml
  AZURE_COMPUTE:         Keith-Compute            # or "serverless"
  AZML_ENV_URI:          ${{ vars.AZML_ENV_URI }} # optional pin to an existing env

jobs:
  build-train-register:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Azure login (federated)
        uses: azure/login@v2
        with:
          auth-type: SERVICE_PRINCIPAL
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      - name: Install / Update Azure ML CLI v2
        run: |
          set -euo pipefail
          az extension add -n ml --upgrade -y
          az ml -h 1>/dev/null

      - name: Configure defaults
        run: |
          set -euo pipefail
          az account set --subscription "${{ vars.AZURE_SUBSCRIPTION_ID }}"
          az configure --defaults group="${AZURE_RESOURCE_GROUP}" workspace="${AZURE_ML_WORKSPACE}" location="${AZURE_LOCATION}"

      - name: Resolve component path
        id: resolve_component
        run: |
          set -euo pipefail
          SRC="${COMPONENT_FILE}"
          [ ! -f "$SRC" ] && { echo "❌ Component YAML not found: ${COMPONENT_FILE}"; exit 1; }
          echo "path=$SRC" >> "$GITHUB_OUTPUT"

      - name: Check current component versions
        id: list_versions
        run: |
          set -euo pipefail
          VER=$(az ml component list --name "${COMPONENT_NAME}" --query "[].version" -o tsv | sort -V | tail -n1 || true)
          echo "highest_version=${VER:-0}" >> "$GITHUB_OUTPUT"

      - name: Resolve compute
        id: resolve_compute
        run: |
          set -euo pipefail
          COMP="${AZURE_COMPUTE:-serverless}"
          if [ "$COMP" = "serverless" ]; then
            echo "compute_uri=serverless" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! az ml compute show --name "$COMP" 1>/dev/null 2>&1; then
            echo "❌ Compute '$COMP' not found in workspace '${AZURE_ML_WORKSPACE}'."
            az ml compute list -o table || true
            exit 1
          fi
          echo "compute_uri=azureml:${COMP}" >> "$GITHUB_OUTPUT"

      - name: Resolve or create environment
        id: resolve_env
        run: |
          set -euo pipefail
          if [ -n "${AZML_ENV_URI:-}" ]; then
            echo "env_uri=${AZML_ENV_URI}" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          ENV_NAME="keith-sklearn-ci"
          ENV_VER="$(date +%Y%m%d%H%M%S)"
          cat > env-temp.yml <<'YAML'
          $schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
          name: keith-sklearn-ci
          version: REPLACE_VERSION
          description: Lightweight sklearn CPU env for CI fallback (auto-generated)
          image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04
          conda_file:
            channels: [conda-forge, defaults]
            dependencies:
              - python=3.10
              - pip
              - pip:
                  - scikit-learn==1.3.2
                  - pandas
                  - numpy
                  - joblib
                  - azureml-mlflow
          YAML
          sed -i "s/REPLACE_VERSION/${ENV_VER}/" env-temp.yml
          az ml environment create --file env-temp.yml
          echo "env_uri=azureml:${ENV_NAME}:${ENV_VER}" >> "$GITHUB_OUTPUT"

      - name: Compute next version and register component
        id: register
        run: |
          set -euo pipefail
          SRC="${{ steps.resolve_component.outputs.path }}"
          CUR="${{ steps.list_versions.outputs.highest_version }}"
          if [[ -z "$CUR" || "$CUR" == "0" ]]; then
            NEXT="$(date +%Y%m%d%H%M%S)"
          elif [[ "$CUR" =~ ^[0-9]+$ ]]; then
            NEXT=$(( CUR + 1 ))
          else
            NEXT="$(date +%Y%m%d%H%M%S)"
          fi
          echo "Next version: ${NEXT}"

          # ---------- Python helper: edit component yaml ----------
          cat > .edit_component.py <<'PY'
import io, re, sys, os
src = sys.argv[1]
out = sys.argv[2]
version = sys.argv[3]
env_uri = sys.argv[4]

text = io.open(src,'r',encoding='utf-8').read()

# ensure version
if re.search(r'(?m)^\s*version\s*:', text):
    text = re.sub(r'(?m)^\s*version\s*:\s*\S+.*$', f'version: {version}', text)
else:
    # insert after 'name:' line if possible
    if re.search(r'(?m)^\s*name\s*:', text):
        text = re.sub(r'(?m)^(\s*name\s*:[^\n]*\n)', r'\1version: '+version+'\n', text, count=1)
    else:
        text = 'version: '+version+'\n'+text

# ensure environment
if re.search(r'(?m)^\s*environment\s*:', text):
    text = re.sub(r'(?m)^\s*environment\s*:\s*.*$', 'environment: '+env_uri, text)
else:
    text = text.rstrip()+'\n\nenvironment: '+env_uri+'\n'

# extract "python <script>"
m = re.search(r'(?m)^\s*command\s*:\s*(.*?)(?:\n[^ \t]|\Z)', text, re.S)
cmd = (m.group(1) if m else '').replace('\n',' ')
cmd = re.sub(r'\s+',' ', cmd).strip()
m2 = re.search(r'python\s+([^\s]+)', cmd)
script = m2.group(1) if m2 else 'train.py'
base = os.path.basename(script)

# try to find the code directory: prefer yaml dir, then common folders
yaml_dir = os.path.dirname(os.path.abspath(src))
candidates = [yaml_dir, 'aml/components', 'components', '.']
code_dir = None
for root in candidates:
    p = os.path.join(root, base)
    if os.path.isfile(p):
        code_dir = root
        break

if not code_dir:
    # last resort: walk shallow
    for r,_,files in os.walk('.'):
        if base in files:
            code_dir = r
            break

if not code_dir:
    print(f"ERROR: could not locate {base}", file=sys.stderr)
    sys.exit(2)

# ensure code:
if re.search(r'(?m)^\s*code\s*:', text):
    text = re.sub(r'(?m)^\s*code\s*:\s*.*$', 'code: '+code_dir, text)
else:
    text = text.rstrip()+'\n\ncode: '+code_dir+'\n'

io.open(out,'w',encoding='utf-8').write(text)
print(base)
PY

          SCRIPT_BASENAME=$(python .edit_component.py "$SRC" component_temp.yml "${NEXT}" "${{ steps.resolve_env.outputs.env_uri }}")
          echo "Resolved script file: ${SCRIPT_BASENAME}"
          echo "----- component_temp.yml (head) -----"
          sed -n '1,140p' component_temp.yml

          az ml component create --file component_temp.yml
          echo "registered_version=${NEXT}" >> "$GITHUB_OUTPUT"

      - name: Normalize pipeline (compute, components)
        id: patch_pipeline
        run: |
          set -euo pipefail
          NEXT="${{ steps.register.outputs.registered_version }}"
          COMP_URI="${{ steps.resolve_compute.outputs.compute_uri }}"
          PL="${PIPELINE_FILE}"
          [ ! -f "$PL" ] && { echo "❌ Pipeline file not found: ${PL}"; exit 1; }

          # ---------- Python helper: patch pipeline yaml ----------
          cat > .patch_pipeline.py <<'PY'
import io, re, sys
pl = sys.argv[1]
out = sys.argv[2]
comp_name = sys.argv[3]
version = sys.argv[4]
compute = sys.argv[5]
text = io.open(pl,'r',encoding='utf-8').read()

# default_compute
if re.search(r'(?m)^\s*default_compute\s*:', text):
    text = re.sub(r'(?m)^\s*default_compute\s*:\s*.*$', 'default_compute: '+compute, text)
else:
    # Prepend a settings block if missing
    text = 'settings:\n  default_compute: '+compute+'\n\n'+text

# bump component reference
text = re.sub(r'(?m)(component:\s*azureml:'+re.escape(comp_name)+r':)\S+', r'\g<1>'+version, text)

io.open(out,'w',encoding='utf-8').write(text)
PY

          python .patch_pipeline.py "$PL" pipeline_temp.yml "${COMPONENT_NAME}" "${NEXT}" "${COMP_URI}"
          echo "tmp_pipeline=pipeline_temp.yml" >> "$GITHUB_OUTPUT"
          echo "----- pipeline_temp.yml (head) -----"
          sed -n '1,120p' pipeline_temp.yml

      - name: Submit pipeline
        id: run_pipeline
        run: |
          set -euo pipefail
          JOB=$(az ml job create --file "${{ steps.patch_pipeline.outputs.tmp_pipeline }}" --query name -o tsv)
          echo "job_name=${JOB}" >> "$GITHUB_OUTPUT"
          echo "✅ Submitted pipeline job: ${JOB}"

      - name: Save job metadata & logs
        if: always()
        run: |
          set -euo pipefail
          JOB=${{ steps.run_pipeline.outputs.job_name }}
          if [ -n "${JOB:-}" ]; then
            az ml job show --name "$JOB" -o json > aml-job.json || true
            mkdir -p aml-job-logs
            az ml job download --name "$JOB" --download-path aml-job-logs --all -y || true
            echo "https://ml.azure.com/experiments/${{ github.event.repository.name }}/runs/${JOB}" > aml-studio-link.txt
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: aml-job-info
          path: |
            aml-job.json
            aml-studio-link.txt
            aml-job-logs/**
