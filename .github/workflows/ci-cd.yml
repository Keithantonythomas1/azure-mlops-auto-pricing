name: aml-mlops-cicd

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AZURE_RESOURCE_GROUP:  MSFT-AI-Class
  AZURE_ML_WORKSPACE:    MyFirstWorkSpace
  AZURE_LOCATION:        eastus
  COMPONENT_NAME:        train_random_forest
  COMPONENT_FILE:        aml/components/train.yml
  PIPELINE_FILE:         aml/pipeline.yml
  AZURE_COMPUTE:         Keith-Compute
  AZML_ENV_URI:          ${{ vars.AZML_ENV_URI }}

jobs:
  build-train-register:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Azure login (federated)
        uses: azure/login@v2
        with:
          auth-type: SERVICE_PRINCIPAL
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      - name: Install / Update Azure ML CLI v2
        run: |
          set -euo pipefail
          az extension add -n ml --upgrade -y
          az ml -h 1>/dev/null

      - name: Configure defaults
        run: |
          set -euo pipefail
          az account set --subscription "${{ vars.AZURE_SUBSCRIPTION_ID }}"
          az configure --defaults group="${AZURE_RESOURCE_GROUP}" workspace="${AZURE_ML_WORKSPACE}" location="${AZURE_LOCATION}"

      - name: Resolve component path
        id: resolve_component
        run: |
          set -euo pipefail
          SRC="${COMPONENT_FILE}"
          [ ! -f "$SRC" ] && { echo "❌ Component YAML not found: ${COMPONENT_FILE}"; exit 1; }
          echo "path=$SRC" >> "$GITHUB_OUTPUT"

      - name: Check current component versions
        id: list_versions
        run: |
          set -euo pipefail
          VER=$(az ml component list --name "${COMPONENT_NAME}" --query "[].version" -o tsv | sort -V | tail -n1 || true)
          echo "highest_version=${VER:-0}" >> "$GITHUB_OUTPUT"

      - name: Resolve compute
        id: resolve_compute
        run: |
          set -euo pipefail
          COMP="${AZURE_COMPUTE:-serverless}"
          if [ "$COMP" = "serverless" ]; then
            echo "compute_uri=serverless" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! az ml compute show --name "$COMP" 1>/dev/null 2>&1; then
            echo "❌ Compute '$COMP' not found in workspace '${AZURE_ML_WORKSPACE}'."
            az ml compute list -o table || true
            exit 1
          fi
          echo "compute_uri=azureml:${COMP}" >> "$GITHUB_OUTPUT"

      - name: Resolve or create environment
        id: resolve_env
        run: |
          set -euo pipefail
          if [ -n "${AZML_ENV_URI:-}" ]; then
            echo "env_uri=${AZML_ENV_URI}" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          ENV_NAME="keith-sklearn-ci"
          ENV_VER="$(date +%Y%m%d%H%M%S)"
          cat > env-temp.yml <<'YAML'
          $schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
          name: keith-sklearn-ci
          version: REPLACE_VERSION
          description: Lightweight sklearn CPU env for CI fallback (auto-generated)
          image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04
          conda_file:
            channels: [conda-forge, defaults]
            dependencies:
              - python=3.10
              - pip
              - pip:
                  - scikit-learn==1.3.2
                  - pandas
                  - numpy
                  - joblib
                  - azureml-mlflow
          YAML
          sed -i "s/REPLACE_VERSION/${ENV_VER}/" env-temp.yml
          az ml environment create --file env-temp.yml
          echo "env_uri=azureml:${ENV_NAME}:${ENV_VER}" >> "$GITHUB_OUTPUT"

      # -------- FIXED STEP: robust YAML command parsing (no awk) --------
      - name: Compute next version and register component
        id: register
        run: |
          set -euo pipefail
          SRC="${{ steps.resolve_component.outputs.path }}"
          CUR="${{ steps.list_versions.outputs.highest_version }}"
          if [[ -z "$CUR" || "$CUR" == "0" ]]; then
            NEXT="$(date +%Y%m%d%H%M%S)"
          elif [[ "$CUR" =~ ^[0-9]+$ ]]; then
            NEXT=$(( CUR + 1 ))
          else
            NEXT="$(date +%Y%m%d%H%M%S)"
          fi
          echo "Next version: ${NEXT}"

          # bump version into temp file
          if grep -Eq '^[[:space:]]*version:' "$SRC"; then
            awk -v v="${NEXT}" 'BEGIN{d=0} /^[[:space:]]*version:[[:space:]]*/{print "version: "v; d=1; next} {print} END{if(!d)print "version: "v}' "$SRC" > component_temp.yml
          else
            awk -v v="${NEXT}" 'BEGIN{a=0} /^[[:space:]]*name:[[:space:]]*/{print; print "version: "v; a=1; next} {print} END{if(!a)print "version: "v}' "$SRC" > component_temp.yml
          fi

          # patch environment
          ENV_URI="${{ steps.resolve_env.outputs.env_uri }}"
          if grep -Eq '^[[:space:]]*environment:' component_temp.yml; then
            sed -E "s|^[[:space:]]*environment:.*$|environment: ${ENV_URI}|" -i component_temp.yml
          else
            printf "\nenvironment: %s\n" "${ENV_URI}" >> component_temp.yml
          fi

          # >>> Robustly read the command block and extract the script after 'python '
          CMD_SCRIPT=$(python - <<'PY'
import re, sys, io
with io.open('component_temp.yml','r',encoding='utf-8') as f:
    y = f.read()
m = re.search(r'(?m)^[ \t]*command:[ \t]*(.*?)(?:\n[^ \t]|\\Z)', y, re.S)
cmd = m.group(1) if m else ''
cmd = cmd.replace('\n',' ')
cmd = re.sub(r'\s+',' ', cmd).strip()
m2 = re.search(r'python\s+([^\s]+)', cmd)
print(m2.group(1) if m2 else '')
PY
)
          if [ -z "${CMD_SCRIPT}" ]; then
            CMD_SCRIPT="train.py"
          fi
          BASE="$(basename "$CMD_SCRIPT")"

          # find the folder that actually contains the script
          YAML_DIR="$(dirname "$SRC")"
          if [ -f "${YAML_DIR}/${BASE}" ]; then
            CODE_DIR="${YAML_DIR}"
          else
            CODE_DIR=$( ( [ -d aml/components ] && find aml/components -maxdepth 2 -type f -name "$BASE" -printf '%h\n' ;
                         [ -d components ]     && find components     -maxdepth 2 -type f -name "$BASE" -printf '%h\n' ;
                         find . -maxdepth 3 -type f -name "$BASE" -printf '%h\n' ) | head -n1 )
            [ -z "$CODE_DIR" ] && { echo "❌ Could not locate ${BASE} in repo."; exit 1; }
          fi

          # patch code:
          if grep -Eq '^[[:space:]]*code:' component_temp.yml; then
            sed -E "s|^[[:space:]]*code:.*$|code: ${CODE_DIR}|" -i component_temp.yml
          else
            printf "\ncode: %s\n" "${CODE_DIR}" >> component_temp.yml
          fi

          echo "---- component_temp.yml (first 140 lines) ----"
          sed -n '1,140p' component_temp.yml

          az ml component create --file component_temp.yml
          echo "registered_version=${NEXT}" >> "$GITHUB_OUTPUT"

      - name: Normalize pipeline (compute, components)
        id: patch_pipeline
        run: |
          set -euo pipefail
          NEXT="${{ steps.register.outputs.registered_version }}"
          COMP_URI="${{ steps.resolve_compute.outputs.compute_uri }}"
          [ ! -f "${PIPELINE_FILE}" ] && { echo "❌ Pipeline file not found: ${PIPELINE_FILE}"; exit 1; }
          cp "${PIPELINE_FILE}" pipeline_temp.yml

          # default_compute
          if grep -qE '^[[:space:]]*default_compute:' pipeline_temp.yml; then
            sed -E "s|(^[[:space:]]*default_compute:).*|\\1 ${COMP_URI}|" -i pipeline_temp.yml
          else
            awk -v c="${COMP_URI}" 'NR==1{print "settings:\n  default_compute: " c} {print}' pipeline_temp.yml > pipeline_temp.yml.new
            mv pipeline_temp.yml.new pipeline_temp.yml
          fi

          # bump train component version
          sed -E "s|(component:[[:space:]]*azureml:${COMPONENT_NAME}:)[^[:space:]]+|\\1${NEXT}|g" -i pipeline_temp.yml

          echo "tmp_pipeline=pipeline_temp.yml" >> "$GITHUB_OUTPUT"
          echo "---- pipeline_temp.yml (first 120 lines) ----"
          sed -n '1,120p' pipeline_temp.yml

      - name: Submit pipeline
        id: run_pipeline
        run: |
          set -euo pipefail
          JOB=$(az ml job create --file "${{ steps.patch_pipeline.outputs.tmp_pipeline }}" --query name -o tsv)
          echo "job_name=${JOB}" >> "$GITHUB_OUTPUT"
          echo "✅ Submitted pipeline job: ${JOB}"

      - name: Save job metadata & logs
        if: always()
        run: |
          set -euo pipefail
          JOB=${{ steps.run_pipeline.outputs.job_name }}
          if [ -n "${JOB:-}" ]; then
            az ml job show --name "$JOB" -o json > aml-job.json || true
            mkdir -p aml-job-logs
            az ml job download --name "$JOB" --download-path aml-job-logs --all -y || true
            echo "https://ml.azure.com/experiments/${{ github.event.repository.name }}/runs/${JOB}" > aml-studio-link.txt
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: aml-job-info
          path: |
            aml-job.json
            aml-studio-link.txt
            aml-job-logs/**
