name: aml-mlops-cicd

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AZURE_RESOURCE_GROUP:  MSFT-AI-Class
  AZURE_ML_WORKSPACE:    MyFirstWorkSpace
  AZURE_LOCATION:        eastus
  COMPONENT_NAME:        train_random_forest
  COMPONENT_FILE:        components/train.yml         # will auto-resolve if missing
  PIPELINE_FILE:         aml/pipeline.yml
  AZURE_COMPUTE:         Keith-Compute               # or "serverless"
  AZML_ENV_URI:          ${{ vars.AZML_ENV_URI }}    # optional hard pin

jobs:
  build-train-register:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Azure login (federated)
        uses: azure/login@v2
        with:
          auth-type: SERVICE_PRINCIPAL
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      - name: Install / Update Azure ML CLI v2
        run: |
          set -euo pipefail
          az extension add -n ml --upgrade -y
          az ml -h 1>/dev/null

      - name: Configure defaults
        run: |
          set -euo pipefail
          az account set --subscription "${{ vars.AZURE_SUBSCRIPTION_ID }}"
          az configure --defaults group="${AZURE_RESOURCE_GROUP}" workspace="${AZURE_ML_WORKSPACE}" location="${AZURE_LOCATION}"

      # --- Resolve component path if default isn't present ---
      - name: Resolve component path
        id: resolve_component
        run: |
          set -euo pipefail
          if [ -f "${COMPONENT_FILE}" ]; then
            echo "path=${COMPONENT_FILE}" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          FOUND=""
          while IFS= read -r -d '' f; do
            if grep -qE '^[[:space:]]*name:[[:space:]]*'${COMPONENT_NAME} "$f"; then
              FOUND="$f"; break
            fi
          done < <(find . -type f \( -path '*/components/*.yml' -o -path '*/components/*.yaml' \) -print0 2>/dev/null)
          [ -z "$FOUND" ] && { echo "❌ No component YAML found"; exit 1; }
          echo "path=$FOUND" >> "$GITHUB_OUTPUT"

      - name: Check current component versions
        id: list_versions
        run: |
          set -euo pipefail
          az ml component list --name "${COMPONENT_NAME}" -o table || true
          VER=$(az ml component list --name "${COMPONENT_NAME}" --query "[].version" -o tsv | sort -V | tail -n1)
          echo "highest_version=${VER:-0}" >> "$GITHUB_OUTPUT"

      # --- Resolve compute URI (serverless or azureml:<short-name>) ---
      - name: Resolve compute
        id: resolve_compute
        run: |
          set -euo pipefail
          COMP="${AZURE_COMPUTE:-serverless}"
          if [ "$COMP" = "serverless" ]; then
            echo "compute_uri=serverless" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! az ml compute show --name "$COMP" 1>/dev/null 2>&1; then
            echo "❌ Compute '$COMP' not found in workspace '${AZURE_ML_WORKSPACE}'."
            az ml compute list -o table || true
            exit 1
          fi
          echo "compute_uri=azureml:${COMP}" >> "$GITHUB_OUTPUT"

      # --- Environment: use override or create a simple workspace env as fallback ---
      - name: Resolve or create environment
        id: resolve_env
        run: |
          set -euo pipefail
          if [ -n "${AZML_ENV_URI:-}" ]; then
            echo "env_uri=${AZML_ENV_URI}" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          ENV_NAME="keith-sklearn-ci"
          ENV_VER="$(date +%Y%m%d%H%M%S)"
          cat > env-temp.yml <<'YAML'
          $schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json
          name: keith-sklearn-ci
          version: REPLACE_VERSION
          description: Lightweight sklearn CPU env for CI fallback (auto-generated)
          image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04
          conda_file:
            channels: [conda-forge, defaults]
            dependencies:
              - python=3.10
              - pip
              - pip:
                  - scikit-learn==1.3.2
                  - numpy
                  - pandas
                  - joblib
          YAML
          sed -i "s/REPLACE_VERSION/${ENV_VER}/" env-temp.yml
          az ml environment create --file env-temp.yml
          echo "env_uri=azureml:${ENV_NAME}:${ENV_VER}" >> "$GITHUB_OUTPUT"

      # --- Build component_temp.yml, bump version, and PATCH env + correct code path ---
      - name: Compute next version and register component (robust code dir)
        id: register
        run: |
          set -euo pipefail
          SRC="${{ steps.resolve_component.outputs.path }}"     # e.g., components/train.yml (source-of-truth)
          CUR="${{ steps.list_versions.outputs.highest_version }}"

          # Next version
          if [[ -z "$CUR" || "$CUR" == "0" ]]; then
            NEXT="$(date +%Y%m%d%H%M%S)"
          elif [[ "$CUR" =~ ^[0-9]+$ ]]; then
            NEXT=$(( CUR + 1 ))
          else
            NEXT="$(date +%Y%m%d%H%M%S)"
          fi
          echo "Next version: ${NEXT}"

          # Temp component
          if grep -Eq '^[[:space:]]*version:' "$SRC"; then
            awk -v v="${NEXT}" '
              BEGIN{done=0}
              /^[[:space:]]*version:[[:space:]]*/ { print "version: " v; done=1; next }
              { print }
              END{ if(done==0) print "version: " v }
            ' "$SRC" > component_temp.yml
          else
            awk -v v="${NEXT}" '
              BEGIN{added=0}
              /^[[:space:]]*name:[[:space:]]*/ { print; print "version: " v; added=1; next }
              { print }
              END{ if(added==0) print "version: " v }
            ' "$SRC" > component_temp.yml
          fi

          # Patch env
          ENV_URI="${{ steps.resolve_env.outputs.env_uri }}"
          if grep -Eq '^[[:space:]]*environment:' component_temp.yml; then
            sed -E "s|^[[:space:]]*environment:.*$|environment: ${ENV_URI}|" -i component_temp.yml
          else
            printf "\nenvironment: %s\n" "${ENV_URI}" >> component_temp.yml
          fi

          # ---- KEY: resolve the real script and its folder for 'code:' ----
          # 1) Guess script name from command (python XYZ.py); fallback to train.py
          CMD_SCRIPT=$(awk '
            BEGIN{FS=":"}
            $1 ~ /command/ {
              # Reconstruct whole command line (handles folded scalars)
              cmd=$0
              while (getline line) {
                if (line ~ /^[[:space:]]+[a-zA-Z_-]+:/) break
                cmd=cmd" "line
              }
              print cmd
              exit
            }' component_temp.yml | sed -E 's/.*python[[:space:]]+([^[:space:]]+).*/\1/' | tr -d '\r' )
          if [ -z "$CMD_SCRIPT" ] || [[ "$CMD_SCRIPT" == "$0" ]]; then
            CMD_SCRIPT="train.py"
          fi
          BASE=$(basename "$CMD_SCRIPT")

          # 2) Prefer folder beside the YAML if script exists there; otherwise search repo
          YAML_DIR="$(dirname "$SRC")"
          if [ -f "${YAML_DIR}/${BASE}" ]; then
            CODE_DIR="${YAML_DIR}"
          else
            # search typical locations first
            CODE_DIR=$( ( [ -d aml/components ] && find aml/components -maxdepth 2 -type f -name "$BASE" -printf '%h\n' ;
                         [ -d components ]     && find components     -maxdepth 2 -type f -name "$BASE" -printf '%h\n' ;
                         find . -maxdepth 3 -type f -name "$BASE" -printf '%h\n' ) | head -n1 )
            if [ -z "$CODE_DIR" ]; then
              echo "❌ Could not locate ${BASE} in repo. Listing tree around YAML:"; ls -la "${YAML_DIR}"; exit 1
            fi
          fi

          echo "Resolved script: ${BASE}"
          echo "Resolved code dir: ${CODE_DIR}"
          ls -la "${CODE_DIR}" || true

          # 3) Patch code: to the correct folder
          if grep -Eq '^[[:space:]]*code:' component_temp.yml; then
            sed -E "s|^[[:space:]]*code:.*$|code: ${CODE_DIR}|" -i component_temp.yml
          else
            printf "\ncode: %s\n" "${CODE_DIR}" >> component_temp.yml
          fi

          echo "----- component_temp.yml (first 140 lines) -----"
          sed -n '1,140p' component_temp.yml

          # Register component
          az ml component create --file component_temp.yml
          echo "registered_version=${NEXT}" >> "$GITHUB_OUTPUT"

      # --- Normalize pipeline: compute + component references ---
      - name: Normalize pipeline (compute, components)
        id: patch_pipeline
        run: |
          set -euo pipefail
          NEXT="${{ steps.register.outputs.registered_version }}"
          COMP_URI="${{ steps.resolve_compute.outputs.compute_uri }}"
          if [ ! -f "${PIPELINE_FILE}" ]; then
            echo "❌ Pipeline file not found: ${PIPELINE_FILE}"
            exit 1
          fi

          cp "${PIPELINE_FILE}" pipeline_temp.yml

          # Patch default_compute
          if grep -qE '^[[:space:]]*default_compute:' pipeline_temp.yml; then
            sed -E "s|(^[[:space:]]*default_compute:).*|\\1 ${COMP_URI}|" -i pipeline_temp.yml
          else
            awk -v c="${COMP_URI}" 'NR==1{print "settings:\n  default_compute: " c} {print}' pipeline_temp.yml > pipeline_temp.yml.new
            mv pipeline_temp.yml.new pipeline_temp.yml
          fi

          # Update our component version
          sed -E "s|(component:[[:space:]]*azureml:${COMPONENT_NAME}:)[^[:space:]]+|\\1${NEXT}|g" -i pipeline_temp.yml

          # If a stray file-based register component exists, map it to our train comp (or remove)
          if grep -qE 'component:[[:space:]]*file:components/register\.yml' pipeline_temp.yml; then
            sed -E "s|component:[[:space:]]*file:components/register\.yml|component: azureml:${COMPONENT_NAME}:${NEXT}|g" -i pipeline_temp.yml
          fi

          echo "tmp_pipeline=pipeline_temp.yml" >> "$GITHUB_OUTPUT"
          echo "----- pipeline_temp.yml (first 100 lines) -----"
          sed -n '1,100p' pipeline_temp.yml

      - name: Submit pipeline
        id: run_pipeline
        run: |
          set -euo pipefail
          JOB=$(az ml job create --file "${{ steps.patch_pipeline.outputs.tmp_pipeline }}" --query name -o tsv)
          echo "job_name=${JOB}" >> "$GITHUB_OUTPUT"
          echo "✅ Submitted pipeline job: ${JOB}"

      - name: Save job metadata and download logs
        if: always()
        run: |
          set -euo pipefail
          JOB=${{ steps.run_pipeline.outputs.job_name }}
          if [ -n "${JOB:-}" ]; then
            az ml job show --name "$JOB" -o json > aml-job.json || true
            mkdir -p aml-job-logs
            az ml job download --name "$JOB" --download-path aml-job-logs --all -y || true
            echo "https://ml.azure.com/experiments/${{ github.event.repository.name }}/runs/${JOB}" > aml-studio-link.txt
            echo "Job status: $(az ml job show --name "$JOB" --query status -o tsv || echo n/a)"
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: aml-job-info
          path: |
            aml-job.json
            aml-studio-link.txt
            aml-job-logs/**
